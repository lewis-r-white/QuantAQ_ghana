---
title: "Particulate Matter (PM) Data Prep"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen=999)
```

### Document Summary

This workflow follows the load_ghana_AQ_data.Rmd file and assumes that we have downloaded data from the cloud and/or obtained data from SD cards.

In this workflow, we: 
- ingest minutely PM data from two sources (QuantAQ cloud + SD card) 
- merge them so gaps in the cloud are filled by SD 
- compute monitor-specific calibration equations from colocation windows (if new colocation has occurred) 
- apply those equations to all subsequent data 
- export corrected minutely time series (pm1, pm2.5, pm10) with the raw values kept alongside 
- calculate hourly & daily summaries with fleet averages and completeness checks - export hourly & daily summaries

The current colocation windows can be found in calibration.yml 
- Window 1 (original fleet): fit each monitor to the fleet average during its colocation window. 
- Window 2 (new fleet): fit each new monitor against an already-calibrated reference monitor from the original fleet (e.g., MOD-PM-00884).

### Prerequisites and expected folders

Before you run anything: 
- Put your YAML config at data_load_and_prep/calibration.yml (example below). 
- Put device group CSVs (lists of monitor IDs) at data/new_fleet.csv and data/original_fleet.csv. Each CSV should have at least one column named monitor. 
- Have SD card CSVs and the cloud CSV in the paths referenced in the code. (If your paths change later, only update them in the “load data” chunk.)

**YAML example**: 
thresholds:
  min_active_monitors: 10
  min_points: 1000
  min_r2: 0.5

colocation_windows:
  - name: "window1_initial_fleet"
    start: "2023-08-16"
    end:   "2023-09-20"
    monitors: "original_fleet"
    reference_monitor: null
  - name: "window2_new_monitors"
    start: "2024-12-16"
    end:   "2025-01-25"
    monitors: "new_fleet"
    reference_monitor: "MOD-PM-00884"

### Load packages, source functions, and load YAML

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
### load packages 

library(here) # file path org
library(lubridate)# working with dates
library(tictoc) # timing
library(DT) # datatables
library(purrr) # applying functions across df
library(tidyverse) # data cleaning and plotting
library(data.table) 
library(sf) # spatial data 
library(viridis) # color pallete 
library(knitr)
library(modelsummary) # table of regressions
library(spdep)
library(gstat)
library(units) 
library(gridExtra)
library(broom)
library(Metrics) 
library(kableExtra) # table creation
library(GGally)
library(yaml)

## load in the colocation window and calibration threshold yaml
config <- yaml::read_yaml(here("data_load_and_prep", "calibration.yml"))

# Should show the thresholds and two windows:
str(config)
```

### Load the data (Cloud and SD)

We load SD card CSVs, stack them, and label them as source = "sd_card".

We also load cloud data once per pollutant using load_pollution_datasets() which returns a list with raw_cloud.

Assumptions (should be satisfied if SD card data processed by QuantAQ and cloud data loaded and saved using previous workflow) 
- SD card files contain timestamp_iso, monitor, and PM columns. 
- Cloud file contains monitor, timestamp, date, hour, and the PM column being loaded.

### Merge the cloud and SD data

We left-join SD onto the cloud by monitor + timestamp and take: 
- the cloud value when present, otherwise the SD value 
- source column telling where the chosen value came from

Expected output: 
- A list of data frames for each pollutant specified. 
- Each data frame with columns: monitor, timestamp, date, hour, <pollutant> (pm1, pm25, and pm10), source

```{r}
# source in function that loads each pollution dataset separately to keep data small and prevent R crashes 
source(here("src", "load_pollution_datasets.R"))

# source in flow that applies load_pollution_datasets.R and merged cloud / sd card data 
source(here("src", "load_and_merge_pm_data.R"))

pollutants <- c("pm1", "pm25", "pm10")

sd_paths <- c(
  here("data/all_measurements/sd/full_sd_card_2024-08-20_to_2025-01-29.csv"),
  here("data/all_measurements/sd/full_sd_card_2025-03-01_to_2025-09-01.csv")
)


cloud_path <- here("data/all_measurements/cloud/ghana_AQ_parent_full_20240816_20250901.csv")


data_loaded <- load_and_merge_all_pm(sd_paths, cloud_path, pollutants)

raw_data       <- data_loaded$cloud
full_sd_card   <- data_loaded$sd
merged_results <- data_loaded$merged
```


### Determine colocation correction equations and build calibration tables

**Run this section only if you want to update or recompute calibration equations** (e.g., new colocations, revised thresholds, new monitors).

If no new calibration is needed, skip this entire section — the next step (“Apply correction equations…”) will automatically load your most recent saved calibration tables from the data/calibration folder.

This section produces a calibration table per pollutant with one row per monitor that passed quality checks.
- We later use this table to correct all minutely data with: corrected = (raw - intercept) / slope

This section supports two mutually exclusive strategies, selected by the window’s reference_monitor in your YAML:

1.  **Fleet-average method** (Window 1, original fleet)
-   Build a fleet average time series each minute using all colocated monitors (or a specified group) when there are at least min_active_monitors reporting.
-   For each monitor, regress monitor_raw \~ fleet_avg to get slope/intercept.

2.  **Reference-monitor method** (Window 2, new fleet)
-   used if a new fleet of monitors was colocated with a previously corrected monitor
-   Correct *the reference* inside the *new window* using its most recent saved coefficients (from previous colocation).
-   For each new monitor, regress monitor_raw \~ reference_corrected.

**Inputs this section expects**
-   merged_results[[p]] for each pollutant (pm1, pm25, pm10) with monitor, timestamp, date, hour, pollutant, source.
-   config with thresholds and windows (your YAML).
-   Group CSVs (e.g., data/original_fleet.csv, data/new_fleet.csv) with a column monitor.
-   For vs-ref windows, the baseline calibration table for that pollutant (e.g., calibration_pm25_window1.csv) so we can correct the reference inside the new window.

**Warning**
-   PM 10 showed weaker linearity. If many PM10 rows fail the thresholds or look implausible (e.g., very large slopes, negative intercepts), you can:
   - increase min_r2
   - skip applying PM10 correction and keep PM10 raw (your apply step
        already supports that if a coef is missing).

**Common pitfalls**
  - No rows produced — usually means there’s no temporal overlap between the reference and targets in the window, or thresholds are too strict.
  - Reference has no prior baseline — Ensure the reference monitor appears in the calibration table for the pollutant, and that fitted_on (or colocation_end) is parseable.

```{r}
source(here("src/calibration_helpers.R"))
source(here("src/calibration_methods.R"))
source(here("src/build_calibration.R"))
source(here("src/load_baseline_calibration.R"))

# specify pollutants 
pollutants <- c("pm1","pm25","pm10")

#read windows from YAML 
windows <- config$colocation_windows

# Load any existing baseline calibration tables from previous runs
baseline_cal <- load_baseline_calibration(pollutants)

# Start with those as the working calibration tables
cal_tables <- baseline_cal


# Loop through each window in order and each pollutant
for (w in windows) {
  window_name <- w$name
  
  for (p in pollutants) {
    prior_tbl <- cal_tables[[p]]
    
    new_tbl <- build_calibration_table_for(
      merged_results[[p]],
      pollutant        = p,
      config           = config,
      window_name      = window_name,
      baseline_cal_tbl = prior_tbl
    )
    
    cal_tables[[p]] <- dplyr::bind_rows(
      prior_tbl %||% tibble(),
      new_tbl %||% tibble()
    )
  }
}

# Final master list of calibration tables per pollutant
cal_master <- cal_tables

## Optional inspection
print(cal_master$pm1,  n = 65)
print(cal_master$pm10, n = 65)
print(cal_master$pm25, n = 65)

test <- cal_master$pm25

# write_csv(cal_master$pm1, here::here("data","calibration", paste0("calibration_pm1.csv")))
# write_csv(cal_master$pm10, here::here("data","calibration", paste0("calibration_pm10.csv")))
# write_csv(cal_master$pm25, here::here("data","calibration", paste0("calibration_pm25.csv")))

```



## fleet average plots 

```{r}
window2 <- config$colocation_windows %>%
  purrr::keep(~ .x$name == "window2_new_monitors") %>%
  .[[1]]

df_w2 <- merged_results$pm25 %>%
  filter(
    date >= as.Date(window2$start),
    date <= as.Date(window2$end)
  )

new_ids <- get_monitor_ids(window2$monitors)

fleet_w2 <- compute_fleet_avg(
  df_w2,
  pollutant = "pm25",
  min_active = config$thresholds$min_active_monitors,
  restrict_ids = new_ids
)
```

```{r}

reg_stats <- function(df, x, y) {
  fit <- lm(reformulate(x, y), data = df)
  
  tibble(
    slope = coef(fit)[2],
    intercept = coef(fit)[1],
    r2 = summary(fit)$r.squared,
    rmse = sqrt(mean(residuals(fit)^2))
  )
}


ref_raw <- df_w2 %>%
  filter(monitor == "MOD-PM-00884") %>%
  select(timestamp, pm25_raw = pm25)

plot_raw <- ref_raw %>%
  inner_join(fleet_w2, by = "timestamp")

stats_raw <- plot_raw %>%
  reg_stats(x = "fleet_avg", y = "pm25_raw")

plot_raw_sample <- plot_raw %>%
  slice_sample(n = 5000)

ggplot(plot_raw_sample, aes(x = fleet_avg, y = pm25_raw)) +
  geom_point(alpha = 0.2, size = 0.8) +
  geom_smooth(
    data = plot_raw,
    method = "lm",
    se = FALSE,
    color = "black"
  ) +
  annotate(
    "text",
    x = Inf, y = -Inf,
    hjust = 1.1, vjust = -0.5,
    label = sprintf(
      "Slope = %.3f\nR² = %.3f\nRMSE = %.1f",
      stats_raw$slope,
      stats_raw$r2,
      stats_raw$rmse
    ),
    size = 4
  ) +
  labs(
    x = "New fleet average PM2.5",
    y = "MOD-PM-00884 raw PM2.5",
    title = "Window 2: Raw MOD-PM-00884 vs New Fleet Average"
  )


```


```{r}
coef_00884 <- cal_master$pm25 %>%
  filter(
    monitor == "MOD-PM-00884",
    window_name == "window1"
  ) 

ref_corrected <- ref_raw %>%
  mutate(
    pm25_corr = (pm25_raw - coef_00884$intercept) / coef_00884$slope
  )

plot_corr <- ref_corrected %>%
  inner_join(fleet_w2, by = "timestamp")

stats_corr <- plot_corr %>%
  reg_stats(x = "fleet_avg", y = "pm25_corr")


plot_corr_sample <- plot_corr %>%
  slice_sample(n = 5000)


ggplot(plot_corr_sample, aes(x = fleet_avg, y = pm25_corr)) +
  geom_point(alpha = 0.2, size = 0.8) +
  geom_smooth(
    data = plot_corr,
    method = "lm",
    se = FALSE,
    color = "black"
  ) +
  annotate(
    "text",
    x = Inf, y = -Inf,
    hjust = 1.1, vjust = -0.5,
    label = sprintf(
      "Slope = %.3f\nR² = %.3f\nRMSE = %.1f",
      stats_corr$slope,
      stats_corr$r2,
      stats_corr$rmse
    ),
    size = 4
  ) +
  labs(
    x = "New fleet average PM2.5",
    y = "MOD-PM-00884 corrected PM2.5",
    title = "Window 2: Corrected MOD-PM-00884 vs New Fleet Average"
  )


```


## Apply correction equations for each monitor if available

We first choose the most recent calibration row per monitor with pick_most_recent(), then join those coefs to the full minutely data and compute: corrected = (raw - intercept) / slope

If a monitor has no coefficients, we keep the raw measurement and set a boolean flag column (e.g., calibrated_pm25 = FALSE)

Save the full corrected output.

Note: 
The new colocation consistently shows slopes around 0.8 and intercepts between 6–15 µg/m³ When I apply these corrections, I’m seeing quite a few negative values at low PM raw concentrations.

My hypothesis is that the reference monitor used for the second colocation (MOD-PM-00884) had the lowest slope (0.82) from the initial colocation fleet-average regression, suggesting it was somewhat less sensitive than the fleet average. When corrected, its PM readings are scaled up by roughly 20%, which may bias its behavior as a reference—especially after a year in the field and under different seasonal conditions (e.g., Harmattan). The second colocation also took place during Harmattan (higher concentrations and more variability), so the regression may not capture low-end behavior as well. Since the new colocations relied on this single reference rather than a fleet average, any bias in the reference is likely transferred to the new monitors. There may also be some inherent sensitivity differences between the older and newer monitors.

```{r}
# source in functions to apply the calibration equations if they exist 
source(here::here("src", "apply_calibration.R"))

# load in calibration tables 
cal_pm1  <- readr::read_csv(here::here("data","calibration","calibration_pm1.csv"),  show_col_types = FALSE)
cal_pm25 <- readr::read_csv(here::here("data","calibration","calibration_pm25.csv"), show_col_types = FALSE)
cal_pm10 <- readr::read_csv(here::here("data","calibration","calibration_pm10.csv"), show_col_types = FALSE)

# pick most recent calibration for each monitor/variable
coef_pm1  <- pick_most_recent(cal_pm1,  "pm1")
coef_pm25 <- pick_most_recent(cal_pm25, "pm25")
coef_pm10 <- pick_most_recent(cal_pm10, "pm10")

# use the merged data 
pm1_merged  <- merged_results$pm1
pm25_merged <- merged_results$pm25
pm10_merged <- merged_results$pm10

#apply calibration 
pm1_corrected <- apply_calibration(
  df = pm1_merged,
  cal_tbl = coef_pm1,
  pollutant = "pm1"
)

pm25_corrected <- apply_calibration(
  df = pm25_merged,
  cal_tbl = coef_pm25,
  pollutant = "pm25"
)

pm10_corrected <- apply_calibration(
  df = pm10_merged,
  cal_tbl = coef_pm10,
  pollutant = "pm10"
)


## SAVE THE CORRECTED OUTPUT 
# 
# write_csv(pm1_corrected, here("data", "pm", "final", "pm1_corrected_20240816_20250901.csv"))
# 
# write_csv(pm10_corrected, here("data", "pm", "final", "pm10_corrected_20240816_20250901.csv"))
# 
# write_csv(pm25_corrected, here("data", "pm", "final", "pm25_corrected_20240816_20250901.csv"))
# 
# write_rds(pm1_corrected, here("data", "pm", "final", "pm1_corrected_20240816_20250901.rds"))
# 
# write_rds(pm10_corrected, here("data", "pm", "final", "pm10_corrected_20240816_20250901.rds"))
# 
# write_rds(pm25_corrected, here("data", "pm", "final", "pm25_corrected_20240816_20250901.rds"))


## CREATE CORRECTED FULL DATASET

pm25_keep <- pm25_corrected %>%
  select(monitor, timestamp, pm25, pm25_raw, calibrated_pm25, source_pm25 = source)

pm1_keep <- pm1_corrected %>%
  select(monitor, timestamp, pm1, pm1_raw, calibrated_pm1, source_pm1 = source)

pm10_keep <- pm10_corrected %>%
  select(monitor, timestamp, pm10, pm10_raw, calibrated_pm10, source_pm10 = source)

# Full-join across pollutants on monitor+timestamp
corrected_full <- list(pm25_keep, pm1_keep, pm10_keep) %>%
  reduce(full_join, by = c("monitor", "timestamp")) %>%
  mutate(
    date = as.Date(timestamp),
    hour = lubridate::hour(timestamp),
    # optional unified source if you want a single column:
    source_any = coalesce(source_pm25, source_pm1, source_pm10)
  ) %>%
  # put columns in a nice order
  relocate(monitor, timestamp, date, hour)


# write_rds(corrected_full, here("data", "pm", "final", "corrected_full_data_20240816-20240901.rds"))
```

### summarize the data based on corrected values

summarize_pollution_times() enforces completeness:
  - Hourly mean requires ≥ 45 min present (75%)
  - Daily mean requires ≥ 18 hours present (75%)
  - Fleet average requires ≥ 10 active monitors in the hour/day

It returns a list with hourly and daily, each including both per-monitor means and a fleet average column.

```{r}
# source function that aggregates data by time scale of interest (hourly, daily)
source(here("src", "summarize_pollution_times.R"))

## Manually specify whether to use corrected data or raw data depending on calibration 
pm1_clean <- pm1_corrected %>%
  mutate(
    pm1_data_summarize = if_else(
      monitor %in% original_fleet$monitor,
      pm1,        # corrected values if in original fleet 
      pm1_raw     # raw values for new fleet. correction equation was leading to a lot of negative readings. 
    )
  )

pm10_clean <- pm10_corrected %>%
  mutate(
    pm10_data_summarize = if_else(
      monitor %in% original_fleet$monitor,
      pm10,        # corrected values if in original fleet 
      pm10_raw     # raw values for new fleet
    )
  )


pm25_clean <- pm25_corrected %>%
  mutate(
    pm25_data_summarize = if_else(
      monitor %in% original_fleet$monitor,
      pm25,        # corrected values if in original fleet 
      pm25_raw     # raw values for new fleet
    )
  )


summarized_pm1 <- summarize_pollution_times(
  pm1_clean, "pm1_data_summarize",
  min_minutes_per_hour = 45,
  min_hours_per_day   = 18,
  min_active_monitors = 10
)


summarized_pm10 <- summarize_pollution_times(
  pm10_clean, "pm10_data_summarize",
  min_minutes_per_hour = 45,
  min_hours_per_day   = 18,
  min_active_monitors = 10
)

summarized_pm25 <- summarize_pollution_times(
  pm25_clean, "pm25_data_summarize",
  min_minutes_per_hour = 45,
  min_hours_per_day   = 18,
  min_active_monitors = 10
)


pm1_community_hourly <- summarized_pm1$hourly %>% 
  rename(mean_pm1 = mean_pm1_data_summarize,
         fleet_average_pm1 = fleet_average_pm1_data_summarize)

pm1_community_daily <- summarized_pm1$daily %>% 
  rename(mean_pm1 = mean_pm1_data_summarize,
         fleet_average_pm1 = fleet_average_pm1_data_summarize)

pm25_community_hourly <- summarized_pm25$hourly %>% 
  rename(mean_pm25 = mean_pm25_data_summarize,
         fleet_average_pm25 = fleet_average_pm25_data_summarize)

pm25_community_daily <- summarized_pm25$daily %>% 
  rename(mean_pm25 = mean_pm25_data_summarize,
         fleet_average_pm25 = fleet_average_pm25_data_summarize)

pm10_community_hourly <- summarized_pm10$hourly %>% 
  rename(mean_pm10 = mean_pm10_data_summarize,
         fleet_average_pm10 = fleet_average_pm10_data_summarize)

pm10_community_daily <- summarized_pm10$daily %>%
  rename(mean_pm10 = mean_pm10_data_summarize,
         fleet_average_pm10 = fleet_average_pm10_data_summarize)
```

### Save the summarized output for analysis

```{r}
# Save as CSV
# write_csv(pm1_community_hourly, here("data", "pm", "summarized", "pm1_community_hourly_20240816-20250901.csv"))
# write_csv(pm25_community_hourly, here("data", "pm", "summarized", "pm25_community_hourly_20240816-20250901.csv"))
# write_csv(pm10_community_hourly, here("data", "pm", "summarized", "pm10_community_hourly_20240816-20250901.csv"))
# 
# write_csv(pm1_community_daily, here("data", "pm", "summarized", "pm1_community_daily_20240816-20250901.csv"))
# write_csv(pm25_community_daily, here("data", "pm", "summarized", "pm25_community_daily_20240816-20250901.csv"))
# write_csv(pm10_community_daily, here("data", "pm", "summarized", "pm10_community_daily_20240816-20250901.csv"))
# 
# 
# # Save as RDS
# write_rds(pm1_community_hourly, here("data", "pm", "summarized", "pm1_community_hourly_20240816-20250901.rds"))
# write_rds(pm25_community_hourly, here("data", "pm", "summarized", "pm25_community_hourly_20240816-20250901.rds"))
# write_rds(pm10_community_hourly, here("data", "pm", "summarized", "pm10_community_hourly_20240816-20250901.rds"))
# 
# write_rds(pm1_community_daily, here("data", "pm", "summarized", "pm1_community_daily_20240816-20250901.rds"))
# write_rds(pm25_community_daily, here("data", "pm", "summarized", "pm25_community_daily_20240816-20250901.rds"))
# write_rds(pm10_community_daily, here("data", "pm", "summarized", "pm10_community_daily_20240816-20250901.rds"))

```


```{r}
# # Create full summarized data with all PMs

# pm25_community_hourly <- pm25_community_hourly %>%
#   select(monitor, date, hour, mean_pm25)
# 
# pm1_community_hourly <- pm1_community_hourly %>%
#   select(monitor, date, hour, mean_pm1)
# 
# pm10_community_hourly <- pm10_community_hourly %>%
#   select(monitor, date, hour, mean_pm10)
# 
# full_hourly_summary <- left_join(pm25_community_hourly, pm1_community_hourly, by = c("monitor", "date", "hour")) %>%
#   left_join(pm10_community_hourly, by = c("monitor", "date", "hour"))
# 
# write_csv(full_hourly_summary, here("data", "pm", "summarized", "modpm00884_hourly_20250901-20251115.csv"))
# 
# 
# pm25_community_daily <- pm25_community_daily %>%
#   select(monitor, date, mean_pm25)
# 
# pm1_community_daily <- pm1_community_daily %>%
#   select(monitor, date, mean_pm1)
# 
# pm10_community_daily <- pm10_community_daily %>%
#   select(monitor, date, mean_pm10)
# 
# full_daily_summary <- left_join(pm25_community_daily, pm1_community_daily, by = c("monitor", "date")) %>%
#   left_join(pm10_community_daily, by = c("monitor", "date"))
# 
# write_csv(full_daily_summary, here("data", "pm", "summarized", "modpm00884_daily_20250901-20251115.csv"))

```





```{r}
## one time tasks 

modpm00884_raw <- read_csv("/Users/lewiswhite/CHAP_columbia/QuantAQ_ghana/data/pm/final/corrected_modpm00884_20240816-20240901.csv") 


summarized_pm1 <- summarize_pollution_times(
  modpm00884_raw, "pm1_raw",
  min_minutes_per_hour = 45,
  min_hours_per_day   = 18,
  min_active_monitors = 10
) 

summarized_pm25 <- summarize_pollution_times(
  modpm00884_raw, "pm25_raw",
  min_minutes_per_hour = 45,
  min_hours_per_day   = 18,
  min_active_monitors = 10
) 

summarized_pm10 <- summarize_pollution_times(
  modpm00884_raw, "pm10_raw",
  min_minutes_per_hour = 45,
  min_hours_per_day   = 18,
  min_active_monitors = 10
) 

pm1_community_hourly <- summarized_pm1$hourly %>%
  select(monitor, date, hour, mean_pm1_raw)
pm10_community_hourly <- summarized_pm10$hourly %>%
  select(monitor, date, hour, mean_pm10_raw)
pm25_community_hourly <- summarized_pm25$hourly %>%
  select(monitor, date, hour, mean_pm25_raw)

mod_pm_00884_summary = left_join(pm1_community_hourly, pm10_community_hourly) %>%
  left_join(pm25_community_hourly)

write_csv(mod_pm_00884_summary, here("data", "pm", "summarized", "modpm00884_raw_hourly_20250901-20251115.csv"))




mod00884_pm1 <- read_rds("/Users/lewiswhite/CHAP_columbia/QuantAQ_ghana/data/pm/final/pm1_corrected_20240816_20250901.rds") %>%
  filter(monitor == "MOD-PM-00884") %>%
  filter(date > as.Date("2025-08-01"))

mod00884_pm10 <- read_rds("/Users/lewiswhite/CHAP_columbia/QuantAQ_ghana/data/pm/final/pm10_corrected_20240816_20250901.rds") %>%
  filter(monitor == "MOD-PM-00884") %>%
  filter(date > as.Date("2025-08-01"))

mod00884_pm25 <- read_rds("/Users/lewiswhite/CHAP_columbia/QuantAQ_ghana/data/pm/final/pm25_corrected_20240816_20250901.rds") %>%
  filter(monitor == "MOD-PM-00884") %>%
  filter(date > as.Date("2025-08-01"))



summarized_pm1 <- summarize_pollution_times(
  mod00884_pm1, "pm1_raw",
  min_minutes_per_hour = 45,
  min_hours_per_day   = 18,
  min_active_monitors = 10
) 

summarized_pm25 <- summarize_pollution_times(
  mod00884_pm25, "pm25_raw",
  min_minutes_per_hour = 45,
  min_hours_per_day   = 18,
  min_active_monitors = 10
) 

summarized_pm10 <- summarize_pollution_times(
  mod00884_pm10, "pm10_raw",
  min_minutes_per_hour = 45,
  min_hours_per_day   = 18,
  min_active_monitors = 10
) 

pm1_community_hourly <- summarized_pm1$hourly %>%
  select(monitor, date, hour, mean_pm1_raw)
pm10_community_hourly <- summarized_pm10$hourly %>%
  select(monitor, date, hour, mean_pm10_raw)
pm25_community_hourly <- summarized_pm25$hourly %>%
  select(monitor, date, hour, mean_pm25_raw)

mod_pm_00884_summary = left_join(pm1_community_hourly, pm10_community_hourly) %>%
  left_join(pm25_community_hourly)

write_csv(mod_pm_00884_summary, here("data", "pm", "summarized", "modpm00884_raw_hourly_20250801-20250901.csv"))


```

